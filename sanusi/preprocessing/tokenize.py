# preprocessing/tokenize.py


def tokenize_text(text):
    from nltk.tokenize import word_tokenize
    return word_tokenize(text)
