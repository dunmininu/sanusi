# preprocessing/tokenize.py

from nltk.tokenize import word_tokenize


def tokenize_text(text):
    return word_tokenize(text)
